{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1AlKKVhx53M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def text_preprocess(mess):\n",
        "\n",
        "    # Check characters to see if they are in punctuation\n",
        "    nopunc = [char for char in mess if char not in string.punctuation]\n",
        "\n",
        "    # Join the characters again to form the string.\n",
        "    nopunc = ''.join(nopunc)\n",
        "    nopunc = nopunc.lower()\n",
        "\n",
        "    # Now just remove any stopwords and non alphabets\n",
        "    nostop = [word for word in nopunc.split() if word.lower() not in stopwords.words('english') and word.isalpha()]\n",
        "    return nostop\n",
        "\n",
        "messages = pd.read_csv(\"super23.csv\", encoding='latin-1')\n",
        "# messages = pd.read_excel('punny.xlsx')\n",
        "# messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis = 1)\n",
        "messages.columns = [\"label\", \"message\"]\n",
        "# print (messages.head(3))\n",
        "messages_train = messages.loc[37816:65736, :]\n",
        "print (messages_train.tail(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwEJRBBDlqrz"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5BucQk16wkr"
      },
      "outputs": [],
      "source": [
        "messages_train[\"message\"] = messages_train[\"message\"].apply(text_preprocess)\n",
        "messages_train[\"message\"] = messages_train[\"message\"].agg(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vec = TfidfVectorizer(encoding = \"latin-1\", strip_accents = \"unicode\", stop_words = \"english\", ngram_range=(3, 3))\n",
        "# vec = TfidfVectorizer(encoding = \"latin-1\", strip_accents = \"unicode\", stop_words = \"english\")\n",
        "features = vec.fit_transform(messages_train[\"message\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEofzqsDQ4Cx"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "clf = SVC()\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# clf = LogisticRegression()\n",
        "\n",
        "spam_detect_model = clf.fit(features, messages_train[\"label\"])\n",
        "predict_train = spam_detect_model.predict(features)\n",
        "print(\"Classification Report \\n\",metrics.classification_report(messages_train[\"label\"], predict_train))\n",
        "print(\"\\n\")\n",
        "print(\"Confusion Matrix \\n\",metrics.confusion_matrix(messages_train[\"label\"], predict_train))\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy of Train dataset : {0:0.3f}\".format(metrics.accuracy_score(messages_train[\"label\"], predict_train)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fjteFILs2I4"
      },
      "outputs": [],
      "source": [
        "messages_test = messages.loc[0:37815, :]\n",
        "print (\"Start\", messages_test.head(3))\n",
        "print (\"End\", messages_test.tail(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCvC9uKXGJ5d"
      },
      "outputs": [],
      "source": [
        "messages_test[\"message\"] = messages_test[\"message\"].apply(text_preprocess)\n",
        "messages_test[\"message\"] = messages_test[\"message\"].agg(lambda x: ' '.join(map(str, x)))\n",
        "\n",
        "features_test = vec.transform(messages_test[\"message\"])\n",
        "print(features_test.shape)\n",
        "\n",
        "label_predictions = spam_detect_model.predict(features_test)\n",
        "print(label_predictions)\n",
        "\n",
        "print(metrics.classification_report(messages_test[\"label\"], label_predictions))\n",
        "print(metrics.confusion_matrix(messages_test[\"label\"], label_predictions))\n",
        "print(\"precision: \", metrics.precision_score(messages_test[\"label\"], label_predictions))\n",
        "print(\"recall: \", metrics.recall_score(messages_test[\"label\"], label_predictions))\n",
        "# Printing the Overall Accuracy of the model\n",
        "print(\"Accuracy of the model: {0:0.3f}\".format(metrics.accuracy_score(messages_test[\"label\"], label_predictions)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}